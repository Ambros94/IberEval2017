\section{Conclusions} \label{sec:conclusion}

In this paper we have presented our participation in the IberEval2017 Classification Of Spanish Election Tweets (COSET) shared task. Five different neural models were explored, in combination with 11 types of preprocessing. No preprocessing emerged to be the best with every kind of model, indicating that the preprocessing pipeline optimization has a big impact on results.
We also explored static vs non-static word embeddings and non-static vectors initialized with pre-trained vectors on a bigger corpus is the best performing combination.


