model_name	test_f1_micro	test_f1_macro
cnn	0.568	0.462830115003
fast_text	0.656	0.558137231374
cnn_lstm	0.608	0.469190101187
b_lstm	0.644	0.506652908178
lstm	0.664	0.557153008077
kim	0.632	0.527627460415
Preprocessing:def _clean_tweet(tweet):
    #p.set_options(p.OPT.URL, p.OPT.RESERVED)
    #tweet = p.clean(tweet)
    #p.set_options(p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER)
    #tweet = p.tokenize(tweet)

    #tokenizer = TweetTokenizer(reduce_len=True)
    #word_list = tokenizer.tokenize(tweet)
    #filtered_words = [word for word in word_list if word not in stopwords.words('spanish')]
    # stemmer = SpanishStemmer()
    # stemmed_words = [stemmer.stem(word=word) for word in filtered_words]
    #tweet = " ".join([word for word in filtered_words])
    return tweet
