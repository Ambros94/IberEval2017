model_name	test_accuracy
cnn	0.518343741729
fast_text	0.445346320346
cnn_lstm	0.627132107023
b_lstm	0.536799804706
lstm	0.467048839939
kim	0.447732040157
Pre-processing:def st_sw(tweet):
    tokenizer = TweetTokenizer(reduce_len=True)
    word_list = tokenizer.tokenize(tweet)
    filtered_words = [word for word in word_list if word not in stopwords.words('spanish')]
    stemmer = SpanishStemmer()
    stemmed_words = [stemmer.stem(word=word) for word in filtered_words]
    tweet = " ".join([word for word in stemmed_words])
    return tweet
