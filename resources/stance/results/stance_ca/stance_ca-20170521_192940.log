model_name	test_accuracy
cnn	0.605897208946
fast_text	0.47385620915
cnn_lstm	0.599740903189
b_lstm	0.541285560018
lstm	0.457815992501
kim	0.491640665579
Pre-processing:def st(tweet):
    tokenizer = TweetTokenizer(reduce_len=True)
    word_list = tokenizer.tokenize(tweet)
    stemmer = SpanishStemmer()
    stemmed_words = [stemmer.stem(word=word) for word in word_list]
    tweet = " ".join([word for word in stemmed_words])
    return tweet
